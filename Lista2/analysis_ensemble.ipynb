{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/CIN/jvcm/mcsenv/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import kdn\n",
    "import pruning\n",
    "import diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../cm1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "498"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "*best 2\n",
      "*red 6\n",
      "1\n",
      "*best 2\n",
      "*red 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/CIN/jvcm/mcsenv/lib/python3.6/site-packages/scipy/stats/stats.py:313: RuntimeWarning: divide by zero encountered in log\n",
      "  log_a = np.log(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "*best 4\n",
      "*red 3\n",
      "0\n",
      "*best 6\n",
      "*red 4\n",
      "1\n",
      "*best 2\n",
      "*red 2\n",
      "2\n",
      "*best 2\n",
      "*red 5\n",
      "0\n",
      "*best 9\n",
      "*red 11\n",
      "1\n",
      "*best 2\n",
      "*red 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/CIN/jvcm/mcsenv/lib/python3.6/site-packages/scipy/stats/stats.py:313: RuntimeWarning: divide by zero encountered in log\n",
      "  log_a = np.log(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "*best 5\n",
      "*red 3\n",
      "0\n",
      "*best 8\n",
      "*red 4\n",
      "1\n",
      "*best 2\n",
      "*red 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/CIN/jvcm/mcsenv/lib/python3.6/site-packages/scipy/stats/stats.py:313: RuntimeWarning: divide by zero encountered in log\n",
      "  log_a = np.log(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "*best 3\n",
      "*red 6\n",
      "0\n",
      "*best 8\n",
      "*red 3\n",
      "1\n",
      "*best 2\n",
      "*red 2\n",
      "2\n",
      "*best 10\n",
      "*red 4\n",
      "0\n",
      "*best 5\n",
      "*red 4\n",
      "1\n",
      "*best 2\n",
      "*red 2\n",
      "2\n",
      "*best 3\n",
      "*red 4\n",
      "0\n",
      "*best 3\n",
      "*red 4\n",
      "1\n",
      "*best 2\n",
      "*red 2\n",
      "2\n",
      "*best 5\n",
      "*red 3\n",
      "0\n",
      "*best 6\n",
      "*red 7\n",
      "1\n",
      "*best 4\n",
      "*red 2\n",
      "2\n",
      "*best 6\n",
      "*red 3\n",
      "0\n",
      "*best 3\n",
      "*red 4\n",
      "1\n",
      "*best 2\n",
      "*red 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/CIN/jvcm/mcsenv/lib/python3.6/site-packages/scipy/stats/stats.py:313: RuntimeWarning: divide by zero encountered in log\n",
      "  log_a = np.log(a)\n",
      "/home/CIN/jvcm/mcsenv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "*best 2\n",
      "*red 6\n",
      "0\n",
      "*best 4\n",
      "*red 3\n",
      "1\n",
      "*best 2\n",
      "*red 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/CIN/jvcm/mcsenv/lib/python3.6/site-packages/scipy/stats/stats.py:313: RuntimeWarning: divide by zero encountered in log\n",
      "  log_a = np.log(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "*best 2\n",
      "*red 3\n",
      "Bagging:\n",
      "Metricas: [0.79541667 0.79940152 0.72043489 0.38333542] \n",
      " \n",
      " \n",
      "\n",
      "Best first:\n",
      "Metricas: [[0.78925    0.76047601 0.68863618 0.35843412]\n",
      " [0.87141667 0.69313889 0.4098133  0.26049062]\n",
      " [0.74316667 0.7539697  0.71953816 0.35886758]]\n",
      "Diversidade: [[0.09452802 0.81033373]\n",
      " [0.21650257 0.46760666]\n",
      " [0.09619347 0.80065363]] \n",
      " \n",
      " \n",
      "\n",
      "Reduce Error:\n",
      "Metricas: [[0.80708333 0.79609343 0.73696314 0.4069846 ]\n",
      " [0.87525    0.61750379 0.28439517 0.1862987 ]\n",
      " [0.74308333 0.77520455 0.71400593 0.34914921]]\n",
      "Diversidade: [[ 0.2385997   0.52832017]\n",
      " [ 0.54378224 -0.08429818]\n",
      " [ 0.17928457  0.63735807]] \n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "cenario = ['Conjunto Original', 'Instâncias Difíceis (kDN > 0.4)', 'Instâncias Fáceis (kDN <= 0.4)']\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "\n",
    "metrics_bag = np.zeros(4)\n",
    "metrics_best = np.zeros((3, 4))\n",
    "metrics_red = np.zeros((3, 4))\n",
    "\n",
    "divers_best = np.zeros((3,2))\n",
    "divers_red = np.zeros((3,2))\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "            \n",
    "    sm = SMOTE()\n",
    "    X_train, y_train = sm.fit_sample(X_train, y_train)\n",
    "\n",
    "    #---------------------------------------BAGGING ORIGINAL---------------------------------------#\n",
    "    bg = BaggingClassifier(Perceptron(max_iter = 150, tol = 0.001),\n",
    "                         n_estimators = 100)\n",
    "    bg.fit(X_train, y_train)\n",
    "    AUX = bg.estimators_[:]\n",
    "    metrics_bag += np.array([bg.score(X_test, y_test),\n",
    "                            roc_auc_score(y_test, bg.predict_proba(X_test)[:,1]),\n",
    "                            geometric_mean_score(y_test, bg.predict(X_test)),\n",
    "                            f1_score(y_test, bg.predict(X_test))])\n",
    "    #---------------------------------------------------------------------------------------------#\n",
    "    \n",
    "    easy = []\n",
    "    hard = []\n",
    "    vis = kdn.kDN(X_train, y_train)\n",
    "    for i, k in enumerate(vis):\n",
    "        if k < 0.4:\n",
    "            easy.append(i)\n",
    "        else: \n",
    "            hard.append(i)\n",
    "            \n",
    "    #--------------------------------------BAGGING PODADO-----------------------------------------#\n",
    "    all_ = list(range(len(y_train)))\n",
    "    valid = [all_, hard, easy]\n",
    "    for i, val in enumerate(valid):\n",
    "        print(i)\n",
    "        bg.estimators_ = AUX[:]\n",
    "        \n",
    "        prune1 = pruning.best_first(bg, X_train[val], y_train[val])\n",
    "        prune2 = pruning.reduce_error(bg, X_train[val], y_train[val])\n",
    "        \n",
    "        #--------------------------------------BEST FIRST-----------------------------------------#\n",
    "        divers_best[i, :] += np.array([diversity.disagreement(prune1, X_train, y_train),\n",
    "                                      diversity.kappa(prune1, X_train, y_train)])\n",
    "        bg.estimators_ = prune1       \n",
    "        metrics_best[i, :] += np.array([bg.score(X_test, y_test),\n",
    "                            roc_auc_score(y_test, bg.predict_proba(X_test)[:,1]),\n",
    "                            geometric_mean_score(y_test, bg.predict(X_test)),\n",
    "                            f1_score(y_test, bg.predict(X_test))])       \n",
    "                \n",
    "        #-------------------------------------REDUCE ERROR----------------------------------------#\n",
    "        divers_red[i, :] += np.array([diversity.disagreement(prune2, X_train, y_train),\n",
    "                                      diversity.kappa(prune2, X_train, y_train)])\n",
    "        bg.estimators_ = prune2\n",
    "        metrics_red[i,:] += np.array([bg.score(X_test, y_test),\n",
    "                            roc_auc_score(y_test, bg.predict_proba(X_test)[:,1]),\n",
    "                            geometric_mean_score(y_test, bg.predict(X_test)),\n",
    "                            f1_score(y_test, bg.predict(X_test))])\n",
    "    \n",
    "    #---------------------------------------------------------------------------------------------#\n",
    "    \n",
    "metrics_bag = metrics_bag / skf.n_splits\n",
    "\n",
    "metrics_best = metrics_best / skf.n_splits\n",
    "metrics_red = metrics_red / skf.n_splits\n",
    "\n",
    "divers_best = divers_best / skf.n_splits\n",
    "divers_red = divers_red / skf.n_splits\n",
    "\n",
    "print('Bagging:')\n",
    "print('Metricas:', metrics_bag, '\\n \\n \\n')\n",
    "print('Best first:')\n",
    "print('Metricas:', metrics_best)\n",
    "print('Diversidade:', divers_best, '\\n \\n \\n')\n",
    "print('Reduce Error:')\n",
    "print('Metricas:', metrics_red)\n",
    "print('Diversidade:', divers_red, '\\n \\n \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
