{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/Menelau/DESlib\n",
      "  Cloning https://github.com/Menelau/DESlib to /tmp/pip-req-build-37eid06k\n",
      "Requirement already satisfied (use --upgrade to upgrade): DESlib==0.3.dev0 from git+https://github.com/Menelau/DESlib in /home/CIN/jvcm/mcsenv/lib/python3.6/site-packages\n",
      "Requirement already satisfied: scikit-learn>=0.19.0 in /home/CIN/jvcm/mcsenv/lib/python3.6/site-packages (from DESlib==0.3.dev0) (0.19.2)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /home/CIN/jvcm/mcsenv/lib/python3.6/site-packages (from DESlib==0.3.dev0) (1.15.1)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /home/CIN/jvcm/mcsenv/lib/python3.6/site-packages (from DESlib==0.3.dev0) (1.1.0)\n",
      "Building wheels for collected packages: DESlib\n",
      "  Running setup.py bdist_wheel for DESlib ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-__myvxy0/wheels/8d/97/f7/014976b54546aa3fc60da2446f9ab6f57727cf478172007b06\n",
      "Successfully built DESlib\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/Menelau/DESlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "from matplotlib.pylab import rcParams\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../pruning_div')\n",
    "import kdn\n",
    "import ih_classifier\n",
    "\n",
    "from deslib.dcs.mcb import MCB\n",
    "from deslib.dcs.ola import OLA\n",
    "from deslib.des.knora_e import KNORAE\n",
    "from deslib.des.des_knn import DESKNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../cm1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "metrics = np.zeros((5,4))\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "       \n",
    "    X_Train, X_test = X[train_index], X[test_index]\n",
    "    y_Train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    sm = SMOTE()\n",
    "    X_Train, y_Train = sm.fit_sample(X_Train, y_Train)\n",
    "    \n",
    "    skf_val = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    for train, val_index in skf.split(X_Train, y_Train):\n",
    "        X_train, X_val = X_Train[train], X_Train[val_index]\n",
    "        y_train, y_val = y_Train[train], y_Train[val_index]\n",
    "        break\n",
    "    \n",
    "#-------------------------------IH MODEL--------------------------------\n",
    "    ih_model = ih_classifier.IHClassifier()\n",
    "    ih_model.fit(X_Train, y_Train)\n",
    "    \n",
    "#-----------------------------------------------------------------------\n",
    "\n",
    "    bg = BaggingClassifier(Perceptron(max_iter = 150, tol = 0.001),\n",
    "                         n_estimators = 100)\n",
    "    bg.fit(X_train, y_train)\n",
    "    \n",
    "#-------------------------------DCS & DES-------------------------------\n",
    "    ola = OLA(bg)\n",
    "    ola.fit(X_val, y_val)\n",
    "    \n",
    "    mcb = MCB(bg)\n",
    "    mcb.fit(X_val, y_val)\n",
    "    \n",
    "    knorae = KNORAE(bg)\n",
    "    knorae.fit(X_val, y_val)\n",
    "    \n",
    "    desknn = DESKNN(bg)\n",
    "    desknn.fit(X_val, y_val)\n",
    "    \n",
    "    models = [ih_model, ola, mcb, knorae, desknn]\n",
    "            \n",
    "#---------------------------------------------------------\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        metrics[i, :] += np.array([accuracy_score(y_test, model.predict(X_test)),\n",
    "                            roc_auc_score(y_test, model.predict(X_test)),\n",
    "                            geometric_mean_score(y_test, model.predict(X_test)),\n",
    "                            f1_score(y_test, model.predict(X_test))])\n",
    "metrics = metrics/skf.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 9, 5\n",
    "barWidth = 0.15\n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(metrics[:3].shape[0])\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "r4 = [x + barWidth for x in r3]\n",
    "\n",
    "# Make the plot\n",
    "plt.bar(r1, metrics[:3, 0], width=barWidth, edgecolor='white', label='Acurácia')\n",
    "plt.bar(r2, metrics[:3, 1], width=barWidth, edgecolor='white', label='AUC')\n",
    "plt.bar(r3, metrics[:3, 2], width=barWidth, edgecolor='white', label='G-Mean')\n",
    "plt.bar(r4, metrics[:3, 3], width=barWidth, edgecolor='white', label='F-Measure')\n",
    "\n",
    "# Add xticks on the middle of the group bars\n",
    "plt.ylim([0., 1.01])\n",
    "plt.xlim([-0.2, 2.65])\n",
    "plt.ylabel('Escore')\n",
    "plt.xticks([r + barWidth for r in range(metrics[:3].shape[0])], ['Modelo IH', 'OLA', 'MCB'])\n",
    "\n",
    "# Create legend & Show graphic\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.title('Comparação entre modelos - DCS')\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame(data = metrics[:3], columns = ['Acurácia', 'AUC', 'G-Mean', 'F-Measure'], index = ['Modelo IH', 'OLA', 'MCB'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 9, 5\n",
    "barWidth = 0.15\n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(metrics[:3].shape[0])\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "r4 = [x + barWidth for x in r3]\n",
    "\n",
    "# Make the plot\n",
    "plt.bar(r1, metrics[[0,3,4], 0], width=barWidth, edgecolor='white', label='Acurácia')\n",
    "plt.bar(r2, metrics[[0,3,4], 1], width=barWidth, edgecolor='white', label='AUC')\n",
    "plt.bar(r3, metrics[[0,3,4], 2], width=barWidth, edgecolor='white', label='G-Mean')\n",
    "plt.bar(r4, metrics[[0,3,4], 3], width=barWidth, edgecolor='white', label='F-Measure')\n",
    "\n",
    "# Add xticks on the middle of the group bars\n",
    "plt.ylim([0., 1.01])\n",
    "plt.xlim([-0.2, 2.65])\n",
    "plt.ylabel('Escore')\n",
    "plt.xticks([r + barWidth for r in range(metrics[:3].shape[0])], ['Modelo IH', 'KNORA-E', 'DES-KNN'])\n",
    "\n",
    "# Create legend & Show graphic\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.title('Comparação entre modelos - DES')\n",
    "plt.show()\n",
    "\n",
    "df = pd.DataFrame(data = metrics[[0,3,4]], columns = ['Acurácia', 'AUC', 'G-Mean', 'F-Measure'], index = ['Modelo IH', 'KNORA-E', 'DES-KNN'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
